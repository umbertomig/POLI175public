{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66a1628f-0686-4f23-ad5f-600b9548fa45",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# POLI 175\n",
    "\n",
    "## Class 02 - What is Machine Learning?\n",
    "\n",
    "Dr. Umberto Mignozzetti\n",
    "\n",
    "UCSD\n",
    "\n",
    "(Slides here follow ISL closely)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eddd8d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Before we start:\n",
    "\n",
    "- No quiz or participation checks until week 03!\n",
    "\n",
    "- This is because I realized you are still choosing classes.\n",
    "\n",
    "- We had no *Podcast* for the previous class, since we had to take the class in a different place.\n",
    "\n",
    "- I will also post on DataHub, which is the software we will use to do the assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a9773",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "- Suppose you are hired as a consultant to help design campaign expenditures for a firm.\n",
    "\n",
    "- And they ask you: Where should we spend our resources? The options are: `TV`, `radio`, and `newspaper`.\n",
    "\n",
    "- They want to maximize the sales revenue.\n",
    "\n",
    "- Where would you spend the money?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aa1253",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "- Let me give you a bit more info: here are the previous advertising expenditures and their effects on sales:\n",
    "\n",
    "![image](img/sales.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819d3163",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "- Did it help?\n",
    "\n",
    "- Some people would say yes, I'd say *not really*.\n",
    "\n",
    "![image](img/sales.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45f26ab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Let's formalize the ideas:\n",
    "\n",
    "- $X$: Matrix of predictors ($X_1$: TV expenditures, $X_2$: radio, $X_3$: newspaper)\n",
    "\n",
    "- $Y$: Response variable\n",
    "\n",
    "- $f(.)$: Unknown function that connects the predictors with the response variable.\n",
    "\n",
    "- $\\varepsilon$: Random error term\n",
    "\n",
    "$$ Y \\ = \\ f(X) + \\varepsilon $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afed4070",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Another example: Do you think your years of study will reflect into a better salary in the future?\n",
    "\n",
    "- $Y$: Future salary\n",
    "\n",
    "- $X$: Years of study\n",
    "\n",
    "![image](img/educ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d048e05",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why estimate $f$?\n",
    "\n",
    "- Our job when doing ML is to estimate $f$. But why do we do that?\n",
    "\n",
    "1. **Prediction**: We want to predict the values of $Y$: $\\hat{Y} = f(\\hat{X})$\n",
    "    \n",
    "$$ E(Y − \\hat{Y})^2 \\ = \\ E[f(X) + \\varepsilon - \\hat{f}(X)]^2 = \\underbrace{[f(X) - \\hat{f}(X)]^2}_{\\text{Reducible}} + \\underbrace{Var(\\varepsilon)}_{\\text{Non-reducible}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf98add8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why estimate $f$?\n",
    "\n",
    "2. **Inference**: We want, as scientists, to understand how $Y$ is related with a set of $X$s.\n",
    "    \n",
    "    1. *Which predictors are associated with the response?*\n",
    "    \n",
    "    2. *What is the relationship between the response and each predictor?*\n",
    "    \n",
    "    3. *Can the relationship between Y and each predictor be adequately summarized using a linear equation, or is the relationship more complicated?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3483d8e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How do we estimate $f$?\n",
    "\n",
    "- Let a set of $n$ observations, $(Y_1, X_1)$, ..., $(Y_n, X_n)$.\n",
    "\n",
    "- We will call these observations the **training set**, since we will use these to estimate the function $f$.\n",
    "\n",
    "- Broadly speaking we have two methods to estimate the $f$ function:\n",
    "\n",
    "    1. Parametric\n",
    "\n",
    "    2. Non-parametric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2c5ddc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How do we estimate $f$?\n",
    "\n",
    "**Parametric**:\n",
    "\n",
    "1. We make an assumption about the functional form, e.g., that the f.f. is linear:\n",
    "\n",
    "$$ Y = \\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_p X_p $$\n",
    "\n",
    "2. After the f.f. is selected, we fit (train) the model using the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515ebe26",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How do we estimate $f$?\n",
    "\n",
    "**Parametric**:\n",
    "\n",
    "$$ \\text{income} \\approx \\beta_0 + \\beta_1 \\times \\text{education} + \\beta_2 \\times \\text{seniority} $$\n",
    "\n",
    "![image](img/linreg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047dbc49",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How do we estimate $f$?\n",
    "\n",
    "**Parametric**:\n",
    "\n",
    "- This parametric approach has advantages. The main one is that it is straightforward to estimate.\n",
    "\n",
    "- However, it is not very flexible, and it does not capture more complex relationships.\n",
    "\n",
    "- We can estimate more flexible relations, but we may *overfit* our estimates.\n",
    "\n",
    "- We can always conjecture the wrong $f$!\n",
    "\n",
    "- In any case, in the parametric models we need to make assumptions regarding the f.f. of $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c9ff4c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How do we estimate $f$?\n",
    "\n",
    "**Non-parametric**:\n",
    "\n",
    "- Does not assume the f.f. of $f$.\n",
    "\n",
    "- Seek an estimate of $f$ that gets as close to the data points as possible, without being too rough or wiggly.\n",
    "\n",
    "- Requires lots of observations.\n",
    "\n",
    "- *Overfitting* becomes a more salient problem.\n",
    "\n",
    "**Overfitting:** The estimation do well in the training set, but when you apply it to other observations, it does poorly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235be97c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How do we estimate $f$?\n",
    "\n",
    "**Non-parametric**: Thin-plate splines\n",
    "\n",
    "![spline](img/spline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33defc5a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Estimation of $f$\n",
    "\n",
    "**Trade-offs:** Flexibility x Interpretability\n",
    "\n",
    "- *Why would we ever choose to use a more restrictive method instead of a very flexible approach?*\n",
    "\n",
    "- If you are a scientist, you may want to interpret the results more than have a flexible but hard-to-understand approach.\n",
    "\n",
    "- Thus, when **inference** is the goal, we may choose a more restrictive model.\n",
    "\n",
    "- When **prediction** is the goal, we may use a more flexible model. It captures more nuanced relationships.\n",
    "\n",
    "- Think self-driving Teslas: you need to predict when to turn, not explain to me.\n",
    "\n",
    "- But the interpretability problem does not go away: think about why some people complain about self-driving Teslas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70995808",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Estimation of $f$\n",
    "\n",
    "**Trade-offs:** Flexibility x Interpretability\n",
    "\n",
    "![flexint](img/flexint.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ac1348",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Estimation of $f$\n",
    "\n",
    "**Approaches:** Supervised x Unsupervised Machine Learning\n",
    "\n",
    "- The machine learning techniques roughly divide into *Supervised* and *Unsupervised* methods\n",
    "\n",
    "- **Supervised:** For each observation $i$, we have a target $Y_i$.\n",
    "\n",
    "- **Unsupervised:** We have **no** target $Y_i$. Only $X_i$s, and we want to make sense of it.\n",
    "\n",
    "- **Semi-Supervised:** We know a few $Y_i$, but we want to predict the $Y_i$s for the majority of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bba45b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Estimation of $f$\n",
    "\n",
    "**Unsupervised approach:**\n",
    "\n",
    "![unsup](img/unsup.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5633fd98",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Accuracy\n",
    "\n",
    "- Too many methods... How to choose?\n",
    "\n",
    "- *There is no free lunch in statistics*: **no one method dominates all others over all possible data sets.**.\n",
    "\n",
    "- We will spend some time choosing methods, and then, choosing the best *tunning* parameters for these methods.\n",
    "\n",
    "- One criterion: \n",
    "\n",
    "**Mean Squared Error (MSE)**\n",
    "\n",
    "$$ MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i − \\hat{f}(x_i))^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc7732b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Accuracy\n",
    "**Mean Squared Error (MSE)**\n",
    "\n",
    "$$ MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i − \\hat{f}(x_i))^2 $$\n",
    "\n",
    "- We can compute the MSE on the *training* data, but what we really want to know is how the MSE performs in *unseen* data.\n",
    "\n",
    "- That's why for most training purposes, we will split our dataset into two parts: *training* and *testing*.\n",
    "\n",
    "- We want to compute the MSE in this *testing* data: it is our best shot at knowing how it is going to behave in real-world applications!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0512ae62",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Accuracy\n",
    "\n",
    "**Mean Squared Error (MSE)**\n",
    "\n",
    "![bvt](img/bvt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339cf8ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Accuracy\n",
    "\n",
    "**Mean Squared Error (MSE)**\n",
    "\n",
    "![bvt](img/bvt2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1613825",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Accuracy\n",
    "\n",
    "- This trade-off is called **Bias-Variance Trade-off**.\n",
    "\n",
    "- When we adopt a more flexible approach, we **decrease** the bias (distance between $f$ and $\\hat{f}$).\n",
    "\n",
    "    - This means that the training MSE decreases.\n",
    "\n",
    "- However, when we adopt a more flexible approach, we **increase** the variance (think overfitting).\n",
    "\n",
    "$$ E(y_0 - \\hat{f}(x_0))^2 \\ = \\ Var(\\hat{f}(x_0)) + [Bias(\\hat{f}(x_0))]^2 + Var(\\varepsilon) $$\n",
    "\n",
    "- Our job is to fit a model that has **low bias** and **low variance**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75fbc0b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Accuracy\n",
    "\n",
    "**Bias-Variance Trade-off**\n",
    "\n",
    "![bvt](img/bvt3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1280d845",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16edb64c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## See you in the next class!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
