{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "243e38f9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# POLI 175 - Lecture 07\n",
    "\n",
    "## Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ae1b7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plan for today\n",
    "\n",
    "- Theory and problems of regression estimates.\n",
    "\n",
    "- Next class: how to estimate regressions using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a185f0fb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regression\n",
    "\n",
    "- Regression analysis is one of the most studied approaches for Supervised ML.\n",
    "\n",
    "- It has been around for a long time: we know it well.\n",
    "\n",
    "- it is a great starting point for learning more sophisticated methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39960d02",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regression\n",
    "\n",
    "- Consider that we run a survey to measure the `prestige` of several professions in the U.S. (We are going to study a survey like this in the next class.)\n",
    "\n",
    "- A few questions about `prestige`:\n",
    "    + Is there a relationship between `prestige` and `income`?\n",
    "    + How strong is the relationship between `prestige` and `income`?\n",
    "    + Which variables are associated with `prestige`?\n",
    "    + How can we accurately predict the prestige of professions not studied in this survey?\n",
    "    + Is the relationship linear?\n",
    "    + Is there a synergy among predictors?\n",
    "    \n",
    "- These are relevant questions, and regression analysis can help us here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456be65d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "### Estimation\n",
    "\n",
    "- It lives for its name! A very simple approach to regression:\n",
    "\n",
    "- Let:\n",
    "    + $y_i$ the variable we want to predict\n",
    "    + $x_i$ is the variable we will be using to make the prediction.\n",
    "    + And if we assume a linear relationship, we want to find a slope $\\beta_1$ and an intercept $\\beta_0$.\n",
    "    + $n$ the number of observations\n",
    "    + $i$ a given observation.\n",
    "    + Thus:\n",
    "\n",
    "$$ y_i \\approx \\beta_0 + \\beta_1 x_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adc4ee7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "### Estimation\n",
    "\n",
    "How do we estimate $\\beta_0$ and $\\beta_1$? \n",
    "\n",
    "![reg](fig1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb0f584",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "### Estimation\n",
    "\n",
    "- We are searching, among all the possible lines, for the one that does `best`.\n",
    "\n",
    "- What does `best` mean in this context?\n",
    "\n",
    "- One concept: minimize the distance between the `predicted` values and the `actual` value.\n",
    "\n",
    "- Predicted value:\n",
    "\n",
    "$$ \\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c890012",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "### Estimation\n",
    "\n",
    "- Actual value:\n",
    "\n",
    "$$ y_i = \\hat{y}_i + e_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i + e_i $$\n",
    "\n",
    "- And `best` here will mean that we minimized the **residuals sum of squares**:\n",
    "\n",
    "$$ RSS \\ = \\ e_1^2 + e_2^2 + \\cdots + e_n^2 $$\n",
    "\n",
    "- It is a well-behaved function on $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d60693",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "### Estimation\n",
    "\n",
    "- With simple optimization, we can find the $\\hat{\\beta}$s that minimize this.\n",
    "\n",
    "![reg](fig2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa65808",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "### Assessing the accuracy of the estimates\n",
    "\n",
    "We rarely know the true estimates $\\beta_1$ and $\\beta_0$ (we only do if we `cook the data`).\n",
    "\n",
    "How do we know how good these $\\hat{\\beta}_1$ and $\\hat{\\beta}_0$ are as an approximation of the true $\\beta$s?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab538779",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "### Assessing the accuracy of the estimates\n",
    "\n",
    "![reg](fig3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed328f76",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "### Assessing the accuracy of the estimates\n",
    "\n",
    "- We find how precise our estimates are by computing the `standard error`.\n",
    "\n",
    "- In some sense, the standard error of the $\\beta_k$ in question is the square root of the variance of it.\n",
    "\n",
    "- The variance, for each of the $\\hat{\\beta}$s in here, is:\n",
    "\n",
    "$$ SE(\\hat{\\beta}_0)^2 = \\sigma^2\\left[\\dfrac{1}{n} + \\dfrac{\\overline{x}^2}{\\sum_i(x_i-\\overline{x})^2}\\right]\\ , \\quad SE(\\hat{\\beta}_1)^2 = \\dfrac{\\sigma^2}{\\sum_i(x_i-\\overline{x})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318e2d65",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "### Assessing the accuracy of the estimates\n",
    "\n",
    "- And since $\\sigma^2 = Var(\\varepsilon)$, i.e., the real error term, we need also to estimate it:\n",
    "\n",
    "$$ \\sigma \\ = \\ \\sqrt{\\dfrac{RSS}{n-2}} $$\n",
    "\n",
    "- These standard errors give us an idea of how much we can `trust` our estimates. The smaller, the better!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070ea153",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "### Assessing the accuracy of the estimates\n",
    "\n",
    "#### Confidence Intervals\n",
    "\n",
    "- We can also put together a `confidence interval` for our estimates:\n",
    "\n",
    "- A 95\\% confidence interval looks like this:\n",
    "\n",
    "$$ \\hat{\\beta}_k \\pm 2 \\times SE(\\hat{\\beta}_k) $$\n",
    "\n",
    "- The number 2 would change depending on the confidence levels you choose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642c69d3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "### Assessing the accuracy of the estimates\n",
    "\n",
    "#### Hypothesis testing\n",
    "\n",
    "- We can also test whether the coefficient could be considered `statistically different` than zero.\n",
    "\n",
    "- We test the hypothesis (called null hypothesis):\n",
    "\n",
    "$$ H_0: \\beta_k = 0 $$\n",
    "\n",
    "- Against the hypothesis (called an alternative hypothesis):\n",
    "\n",
    "$$ H_a: \\beta_k \\neq 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df753641",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "### Assessing the accuracy of the estimates\n",
    "\n",
    "#### Hypothesis testing\n",
    "\n",
    "And to do that, we put together the `t-statistic`:\n",
    "\n",
    "$$ t = \\dfrac{\\hat{\\beta}_k - 0}{SE(\\hat{\\beta}_k)} \\ \\sim \\ \\text{Student's-T}(n-2) $$\n",
    "\n",
    "- And the p-value is the probability of finding a value larger than $t$ in the Student's-T distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923b83c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "### Assessing the accuracy of the whole model\n",
    "\n",
    "#### RSE\n",
    "\n",
    "The residual standard error is one of the best measures of the fit quality.\n",
    "\n",
    "As we said in the second class, it is the criterium we use for most Supervised Machine Learning models.\n",
    "\n",
    "It is defined as:\n",
    "\n",
    "$$ \\text{RSE} \\ = \\ \\sqrt{\\dfrac{RSS}{n-2}} \\ = \\ \\sqrt{\\dfrac{\\sum_i(y_i - \\hat{y}_i)^2}{n-2}} $$\n",
    "\n",
    "The lower, the better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a594bc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "### Assessing the accuracy of the whole model\n",
    "\n",
    "#### $R^2$\n",
    "\n",
    "The $R^2$ is a measure of goodness-of-fit.\n",
    "\n",
    "It is widely used because it is between zero and one.\n",
    "\n",
    "The proportion of the variability of $Y$ that is explained by modeling it using $X$.\n",
    "\n",
    "It is defined as:\n",
    "\n",
    "$$ \\text{R}^2 \\ = \\ \\dfrac{TSS - RSS}{TSS} \\  = \\ 1 - \\dfrac{RSS}{TSS} $$\n",
    "\n",
    "And the total sum of squares is defined as $TSS = \\sum_i(y_i-\\overline{y})^2$. \n",
    "\n",
    "The higher the $R^2$, the better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e86b76",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "### Assessing the accuracy of the whole model\n",
    "\n",
    "#### F-Statistic\n",
    "\n",
    "- Not now! First, multiple Linear Regression :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6629990c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "- We use multiple linear regression when we have multiple predictors for the same outcome variable.\n",
    "\n",
    "- Let:\n",
    "    + $y_i$ the variable we want to predict\n",
    "    + $x_{ik}$ are the variables we will use to make the prediction.\n",
    "    + $p$: number of predictors.\n",
    "    + And if we assume a linear relationship, we want to find a slope $\\beta_1$ and an intercept $\\beta_0$.\n",
    "    + $n$ the number of observations\n",
    "    + $i$ a given observation\n",
    "    + $k$ and $l$: given predictors\n",
    "    + Thus:\n",
    "    \n",
    "$$ y_i \\ = \\ \\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + \\cdots + \\beta_px_{ip} + \\varepsilon $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcdda5f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimation\n",
    "\n",
    "- And the residual sum of squares is defined similarly as before, but we optimize over more parameters:\n",
    "\n",
    "$$ \\text{RSS} \\ = \\ \\sum_ie_i^2 \\ = \\ \\sum_i(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1x_{i1} - \\cdots - \\hat{\\beta}_px_{ip})^2 $$\n",
    "\n",
    "![reg](fig4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44c985b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Assessing accuracy\n",
    "\n",
    "#### F-Statistic\n",
    "\n",
    "- Now, yes! The F-Statistic tests whether at least one predictor are different from zero.\n",
    "\n",
    "- The null hypothesis is:\n",
    "\n",
    "$$ H_0: \\ \\beta_1 = \\beta_2 = \\cdots = \\beta_p $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a2bbbf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Assessing accuracy\n",
    "\n",
    "#### F-Statistic\n",
    "\n",
    "- And the alternative hypothesis is:\n",
    "\n",
    "$$ H_a: \\ \\exists k \\in \\{1, \\cdots, p\\}, \\ s.t. \\ \\beta_k \\neq 0 $$\n",
    "\n",
    "- And $F$ is equal to:\n",
    "\n",
    "$$ \\text{F} \\ = \\ \\dfrac{\\frac{TSS-RSS}{p}}{\\frac{RSS}{n-p-1}} \\ \\sim \\ F(p, n-p-1) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42338272",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Assessing accuracy\n",
    "\n",
    "#### F-Statistic\n",
    "\n",
    "- Why is this a good test? Because under the null hypothesis:\n",
    "\n",
    "$$ \\mathbb{E}\\left[\\dfrac{TSS-RSS}{p}\\right] = \\mathbb{E}\\left[\\dfrac{RSS}{n-p-1}\\right] = \\sigma^2 $$\n",
    "\n",
    "- And so, $F \\approx 1$ under $H_0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81fba1b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### F-Statistic for model selection\n",
    "\n",
    "- Suppose we have $\\{1, \\cdots, l \\}$ predictors, but we could add $\\{l+1, \\cdots, p \\}$ extra predictors in our model.\n",
    "\n",
    "- Does that make sense? We can test the RSS of the restricted model against the RSS of the full model.\n",
    "\n",
    "- The null hypothesis is:\n",
    "\n",
    "$$ H_0: \\ \\beta_{l+1} = \\cdots = \\beta_{p} = 0 $$\n",
    "\n",
    "- And the F-Stat:\n",
    "\n",
    "$$ \\text{F} \\ = \\ \\dfrac{\\frac{RSS_0-RSS}{p-l}}{\\frac{RSS}{n-p-1}} \\ \\sim \\ F(p-l, n-p-1) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f164fc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Deciding on important variables\n",
    "\n",
    "- Several criteria can be used. We will discuss later their trade-offs.\n",
    "\n",
    "- But we have a couple of automated ways to select them that are easier to implement:\n",
    "\n",
    "1. **Forward selection**:\n",
    "    + Start with the null model and fit $p$ regressions for each predictor. \n",
    "    + Add to the model the variable that results in the lowest RSS.\n",
    "    + Repeat until some stopping rule is satisfied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcfe002",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Deciding on important variables\n",
    "\n",
    "2. **Backward selection**:\n",
    "    + Start with the full model, with all $p$ predictors. \n",
    "    + Remove the variable with the lowest p-value.\n",
    "    + Fit the new model with p-1 variables.\n",
    "    + Repeat until some stopping rule is satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa19cf6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Deciding on important variables\n",
    "\n",
    "3. **Mixed selection**:\n",
    "    + Start with the null model and fit $p$ regressions for each predictor.\n",
    "    + Add to the model the variable that results in the lowest RSS.\n",
    "    + Look at the p-value and remove it if it drops under a certain threshold.\n",
    "    + Repeat until some stopping rule is satisfied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eace45",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d252e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# See you next class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94ad227",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Model fit and RSE\n",
    "\n",
    "- **R$^2$**: Captures the fraction of variance explained by the model.\n",
    "    + The higher, the better.\n",
    "    + But the problem is that it always increases when adding variables.\n",
    "\n",
    "- **RSE**:\n",
    "\n",
    "$$ \\text{RSE} \\ = \\ \\sqrt{\\dfrac{RSS}{n-p-1}} $$\n",
    "\n",
    "    + The lower, the better. \n",
    "    + Good thing: it may increase or decrease.\n",
    "    + If we start adding things that do not help, it increases!\n",
    "    \n",
    "## Other important topics\n",
    "\n",
    "### Qualitative predictors\n",
    "\n",
    "In many situations in social sciences, we have qualitative predictors:\n",
    "\n",
    "- Treated x non-treated status\n",
    "- Dummy variables\n",
    "- Discrete variables.\n",
    "\n",
    "These variables affect the model by changing the intercept of the regression line.\n",
    "\n",
    "#### Binary variable\n",
    "\n",
    "For example, suppose that you are studying the personal rating of the government so far, and you have whether the person voted democrat:\n",
    "\n",
    "$$\n",
    "  x_i=\\left\\{\n",
    "  \\begin{array}{@{}ll@{}}\n",
    "    1, & \\text{if voted democrat} \\\\\n",
    "    0, & \\text{otherwise}\n",
    "  \\end{array}\\right.\n",
    "$$\n",
    "\n",
    "And the model here would look like this:\n",
    "\n",
    "$$\n",
    "  y_i = \\beta_0 + \\beta_1x_i + \\varepsilon_i=\\left\\{\n",
    "  \\begin{array}{@{}ll@{}}\n",
    "    \\beta_0 + \\beta_1 + \\varepsilon_i, & \\text{if voted democrat} \\\\\n",
    "    \\beta_0 + \\varepsilon_i, & \\text{otherwise}\n",
    "  \\end{array}\\right.\n",
    "$$\n",
    "\n",
    "*Meaning*: Voting democrat would make the person start from a different baseline evaluation of the government.\n",
    "\n",
    "- You can have multiple levels here.\n",
    "\n",
    "### Non-linearity\n",
    "\n",
    "We can have non-linearity in many ways.\n",
    "\n",
    "1. We can have synergies between predictors.\n",
    "\n",
    "2. We can have non-linear relationships for the same predictor, e.g., diminishing returns for a given variable.\n",
    "\n",
    "We will study those in the following lecture.\n",
    "\n",
    "\n",
    "## Potential Problems in our Estimates\n",
    "\n",
    "Several plots can help us diagnose the quality of our model.\n",
    "\n",
    "**Warning**: Find and analyzing these violations is more of an art.\n",
    "\n",
    "- In any case, be mindful that a careful analysis is frequent enough to ensure you have a `good` model.\n",
    "\n",
    "We are going to look at some of them.\n",
    "\n",
    "### Non-linearity\n",
    "\n",
    "When the best relationship is non-linear, you could have done better using a different functional form.\n",
    "\n",
    "The plot to detect this is residual in the y-axis against the fitted values in the x-axis:\n",
    "\n",
    "![reg](fig5.png)\n",
    "\n",
    "- Plot: Fitted Values x Raw Residuals\n",
    "\n",
    "- The best: You should find no patterns.\n",
    "\n",
    "- The ugly: A discernible pattern tells you that you could have done better with a more flexible model.\n",
    "\n",
    "### Auto-correlation\n",
    "\n",
    "This is more of a problem for time-series data. It happens when the error terms are correlated.\n",
    "\n",
    "This means that the values of a given variable at $t$ depend on its value at $t-1$. \n",
    "\n",
    "For example, if you look at the residual over time, no auto-correlation means that the residuals against time do not show any pattern.\n",
    "\n",
    "![reg](fig6.png)\n",
    "\n",
    "- Plot: Time x Raw Residuals\n",
    "\n",
    "- The best: you should see no discernible pattern when you plot residuals against time.\n",
    "\n",
    "- The ugly: you may find a statistically significant relationship where there is none.\n",
    "\n",
    "### Heteroscedasticity\n",
    "\n",
    "- It is fancy wording to say that the variance in error is not constant.\n",
    "\n",
    "- It usually means that you are better at fitting some range of the predictors than others.\n",
    "\n",
    "![reg](fig7.png)\n",
    "\n",
    "- Plot: Fitted Values x Raw Residuals\n",
    "\n",
    "- The best: You should find no patterns.\n",
    "\n",
    "- The ugly: A funnel-shaped figure tells you that you may have heteroscedasticity. It invalidates your standard errors.\n",
    "\n",
    "### Outliers\n",
    "\n",
    "- Outliers are values very far away from most values predicted by the model.\n",
    "\n",
    "- Sometimes, it is correct, but frequently it may tell you that you made a mistake in collecting the data!\n",
    "\n",
    "![reg](fig8.png)\n",
    "\n",
    "- Plot: Fitted x Studentizided residuals\n",
    "\n",
    "- The best: You should find no extreme values in the plot.\n",
    "\n",
    "- The ugly: An extreme value can affect your RSE, $R^2$, and mess with p-values.\n",
    "\n",
    "### High Leverage\n",
    "\n",
    "- Have very unusual $x_i$ values that could potentially tilt the regression line towards them.\n",
    "\n",
    "- If high leverage and outlier, bad combination!\n",
    "\n",
    "![reg](fig9.png)\n",
    "\n",
    "- Plot: Leverage x Studentizided residuals\n",
    "\n",
    "- The best: You should find no extreme values in the plot.\n",
    "\n",
    "- The ugly: An extreme value can affect your fit.\n",
    "\n",
    "### Multicollinearity\n",
    "\n",
    "- Multicollinearity is a situation when your predictors are highly correlated.\n",
    "\n",
    "- In extreme cases, it messes up with the computations in your model.\n",
    "\n",
    "![reg](fig10.png)\n",
    "\n",
    "- Plot: Leverage x Studentizided residuals\n",
    "\n",
    "- The best: You should find no extreme values in the plot.\n",
    "\n",
    "- The ugly: An extreme value can affect your fit."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
